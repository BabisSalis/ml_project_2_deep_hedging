# CS-433_ML_Project_2_Deep_Hedging

해야할 것

- probabilistic exploitation: epsilon greedy 같은걸로 noise 추가.
- 현재는 OU 프로세스임.

- reward normalize 할 필요?
- training 방식의 변화? update 는 매 time step 마다 하는지? 그리고 target net update 는 언제 하는지?

- reward measure 방식은?

- hedge env 에 맞게 obj function 다시 재정의 필요. 그리고 Q_1, Q_2 만들고, target network 만들것.
