{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.paths\n",
    "sys.path.insert(0, '/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/src')\n",
    "sys.path.insert(1, '/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'paths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/dataGen.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/dataGen.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m norm\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/dataGen.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msimulation\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/dataGen.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menv\u001b[39;00m \u001b[39mimport\u001b[39;00m StockTradingEnv\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/dataGen.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magent\u001b[39;00m \u001b[39mimport\u001b[39;00m DDPG_Hedger\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/dataGen.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnetwork\u001b[39;00m \u001b[39mimport\u001b[39;00m MLP\n",
      "File \u001b[0;32m~/Desktop/ml_project_2_deep_hedging/src/env.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m \u001b[39mimport\u001b[39;00m spaces\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpaths\u001b[39;00m \u001b[39mimport\u001b[39;00m DATA_ROOT\n\u001b[1;32m      9\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mStockTradingEnv\u001b[39;00m(gym\u001b[39m.\u001b[39mEnv):\n\u001b[1;32m     10\u001b[0m     \u001b[39m\"\"\"Environment for agent, consists of __init__, step, and reset functions\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'paths'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm\n",
    "from simulation import *\n",
    "from env import StockTradingEnv\n",
    "from agent import DDPG_Hedger\n",
    "from network import MLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data and appply classical hedging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 20 # length of simulation 20=1 month, 60 = three months\n",
    "S0 = 100 # starting price\n",
    "K = 100 # strike price\n",
    "sigma = 0.2 # volatility\n",
    "r = 0 # risk-free rate\n",
    "q = 0 # dividend yield\n",
    "mu = 0.05 # expected return on stock\n",
    "kappa = 0.01 # trading cost per unit traded\n",
    "dt = 1 # hedging time step\n",
    "notional = 100 # how many stocks the option is on\n",
    "rho = -0.4 # correlation of stochastic volatility process\n",
    "v = 0.6\n",
    "sigma0 = 0.2 # starting volatility\n",
    "c = 1.5 #standard deviation coefficient\n",
    "ds = 0.01\n",
    "\n",
    "n = 3000 # number of simulatied paths\n",
    "days = 250 # number of days in a year\n",
    "freq = 1 # trading frequency\n",
    "np.random.seed(12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1st run: save train data\n",
    "- 2nd run or more: ignore this process and import data and run afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 9533.65it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 4765.68it/s]\n",
      "D:\\work/Personal/ml_project_2_deep_hedging/src\\simulation.py:124: RuntimeWarning: invalid value encountered in divide\n",
      "  imp_vol = np.where(f == K, atm, atm * xi / xi_func)\n"
     ]
    }
   ],
   "source": [
    "S_gbm, p_gbm, d_gbm = simulateGBM(n, T, dt, S0, mu, r, q, sigma, days, freq, K)\n",
    "\n",
    "S_sabr, s_sabr, iv_sabr, p_sabr, delta_sabr, delta_sabr_bl = simulateSABR(\n",
    "    n, T, dt, S0, mu, r, q, sigma, days, freq, rho, ds, v, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classical hedging implementations (trading strategies)\n",
    "trading_gbm, holding_gbm = hedgingStrategy(\"GBM\",notional, d_gbm, 0)\n",
    "trading_sabr, holding_sabr, trading_sabr_bl, holding_sabr_bl = hedgingStrategy(\"SABR\",notional, delta_sabr, delta_sabr_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accounting PnL\n",
    "APL_gbm, holding_lagged_gbm = APL_process(S_gbm, p_gbm*notional, holding_gbm, K, notional, kappa)\n",
    "APL_sabr, holding_lagged_sabr = APL_process(S_sabr, p_sabr*notional, holding_sabr, K, notional, kappa)\n",
    "APL_sabr_bl, holding_lagged_sabr_bl = APL_process(S_sabr, p_sabr*notional, holding_sabr_bl, K, notional, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation:\n",
    "# Y(0) (take mean), \n",
    "# mean of  cost as percentage of option price,\n",
    "# std of  cost as percentage of option price.\n",
    "\n",
    "Y_gbm, mPerc_gbm, stdPerc_gbm = evaluate(APL_gbm, p_gbm, c, notional) \n",
    "Y_sabr, mPerc_sabr, stdPerc_sabr = evaluate(APL_sabr, p_sabr, c, notional)\n",
    "Y_sabr_bl, mPerc_sabr_bl, stdPerc_sabr_bl = evaluate(APL_sabr_bl, p_sabr, c, notional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM\n",
      "Y0:  135.3827886076877\n",
      "mean cost (%):  0.3017732559712498\n",
      "std cost (%):  0.19880406280782928\n",
      "\n",
      "\n",
      "SABR delta\n",
      "Y0:  136.3208466308123\n",
      "mean cost (%):  0.302091636099821\n",
      "std cost (%):  0.20136328646715285\n",
      "\n",
      "\n",
      "SABR Bartlett\n",
      "Y0:  136.38926780116168\n",
      "mean cost (%):  0.3026634253760105\n",
      "std cost (%):  0.2011842428444716\n"
     ]
    }
   ],
   "source": [
    "print(\"GBM\")\n",
    "print(\"Y0: \", np.mean(Y_gbm))\n",
    "print(\"mean cost (%): \", mPerc_gbm)\n",
    "print(\"std cost (%): \", stdPerc_gbm)\n",
    "print(\"\\n\")\n",
    "print(\"SABR delta\")\n",
    "print(\"Y0: \", np.mean(Y_sabr))\n",
    "print(\"mean cost (%): \", mPerc_sabr)\n",
    "print(\"std cost (%): \", stdPerc_sabr)\n",
    "print(\"\\n\")\n",
    "print(\"SABR Bartlett\")\n",
    "print(\"Y0: \", np.mean(Y_sabr_bl))\n",
    "print(\"mean cost (%): \", mPerc_sabr_bl)\n",
    "print(\"std cost (%): \", stdPerc_sabr_bl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 20)\n",
      "(6000, 20)\n"
     ]
    }
   ],
   "source": [
    "result_folder_path = f\"data/{T//20}month/{freq}d\"\n",
    "os.makedirs(result_folder_path, exist_ok=True)\n",
    "\n",
    "# define data\n",
    "# save to csv file\n",
    "np.savetxt(f'data/{T//20}month/{freq}d/asset_price_GBM_sim.csv', S_gbm, delimiter=',')\n",
    "np.savetxt(f'data/{T//20}month/{freq}d/option_price_GBM_sim.csv', p_gbm*notional, delimiter=',')\n",
    "np.savetxt(f'data/{T//20}month/{freq}d/asset_price_SABR_sim.csv', S_sabr, delimiter=',')\n",
    "np.savetxt(f'data/{T//20}month/{freq}d/option_price_SABR_sim.csv', p_sabr*notional, delimiter=',')\n",
    "\n",
    "\n",
    "S_mixed = np.vstack((S_gbm, S_sabr))\n",
    "p_mixed = np.vstack((p_gbm*notional, p_sabr*notional))\n",
    "print(S_mixed.shape)\n",
    "print(p_mixed.shape)\n",
    "np.savetxt(f\"data/{T//20}month/{freq}d/asset_price_mixed_sim.csv\", S_mixed, delimiter=\",\")\n",
    "np.savetxt(f\"data/{T//20}month/{freq}d/option_price_mixed_sim.csv\", p_mixed, delimiter=\",\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep RL Method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env = StockTradingEnv(maturity=1, frequency=1, data_type=\"GBM\", test_env=True)\n",
    "\n",
    "# set same dataset as delta hedging\n",
    "env.asset_price = S_gbm\n",
    "env.option_price = p_gbm\n",
    "\n",
    "nState, nAction = env.observation_space.shape[0], \\\n",
    "                    env.action_space.shape[0]  # 3, 1\n",
    "\n",
    "# we use hidden layer size of 32, 64 as the author used.\n",
    "actor = MLP(nState, 16, nAction, \"Sigmoid\")\n",
    "qnet_1 = MLP(nState + nAction, 16, nAction, \"\")\n",
    "qnet_2 = MLP(nState + nAction, 16, nAction, \"\")\n",
    "agent = DDPG_Hedger(actor, qnet_1, qnet_2, 0, 0, 1, 32)\n",
    "agent.load('v8_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/dataGen.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/dataGen.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m normalized_state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnormalize(state)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/dataGen.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# action without exploration\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/dataGen.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mact(normalized_state, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/dataGen.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m next_state, reward, done \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/dataGen.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m state \u001b[39m=\u001b[39m next_state\n",
      "File \u001b[0;32m~/Desktop/ml_project_2_deep_hedging/src/agent.py:79\u001b[0m, in \u001b[0;36mDDPG_Hedger.act\u001b[0;34m(self, state, epsilon, isPrint)\u001b[0m\n\u001b[1;32m     77\u001b[0m     action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactor(x)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     80\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mclip(action \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m100.0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/ml_project_2_deep_hedging/src/network.py:31\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 31\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m     32\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactiv_layers\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m     33\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_indice, rewards_path, action_path = [], [], []\n",
    "for i in range(n):\n",
    "    state = env.reset()\n",
    "    env.path_idx = i\n",
    "    \n",
    "    path_indice.append(env.path_idx)\n",
    "    rewards, actions = [], [0]\n",
    "    done = False\n",
    "    \n",
    "    if i%1000 == 0:\n",
    "        print(f'Episode {i}')\n",
    "    while not done:\n",
    "        normalized_state = env.normalize(state)\n",
    "        \n",
    "        # action without exploration\n",
    "        action = agent.act(normalized_state, 0)\n",
    "        \n",
    "        next_state, reward, done = env.step(action)\n",
    "\n",
    "        state = next_state\n",
    "        rewards.append(np.round(reward, 2))\n",
    "        actions.append(np.round(action, 2)) # each episode [0.99, 13.20 ... 100 ] shape (1,60) \n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    rewards_path.append(rewards) # <- (numEpisode=25000, 60)\n",
    "    action_path.append(actions) # (numEpisode=25000, 60) = holding_gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get action array as holding gbm\n",
    "apl_gbm_rl, holding_lagged_rl = APL_process(S_gbm, p_gbm*notional, np.array(action_path), K, notional, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_gbm_rl, mPerc_gbm_rl, stdPerc_gbm_rl = evaluate(apl_gbm_rl, p_gbm, c, notional) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM\n",
      "Y0:  232.5832075191567\n",
      "mean cost (%):  0.3103369148956763\n",
      "std cost (%):  0.18994841560819478\n",
      "GBM RL\n",
      "Y0:  1138.6801914838259\n",
      "mean cost (%):  1.551102008324295\n",
      "std cost (%):  0.9087786063302595\n"
     ]
    }
   ],
   "source": [
    "print(\"GBM\")\n",
    "print(\"Y0: \", np.mean(Y_gbm))\n",
    "print(\"mean cost (%): \", mPerc_gbm)\n",
    "print(\"std cost (%): \", stdPerc_gbm)\n",
    "\n",
    "print(\"GBM RL\")\n",
    "print(\"Y0: \", np.mean(Y_gbm_rl))\n",
    "print(\"mean cost (%): \", mPerc_gbm_rl)\n",
    "print(\"std cost (%): \", stdPerc_gbm_rl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode total reward histograms (classic delta vs RL agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_episode_rewards_gbm = np.sum(np.asarray(APL_gbm), axis=1)\n",
    "total_episode_rewards_agent = np.sum(np.asarray(rewards_path), axis=1)\n",
    "plt.hist(total_episode_rewards_agent,bins=40,label='agent')\n",
    "plt.hist(total_episode_rewards_gbm,bins=40,label='classical (GBM)')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions during a path (classic delta vs RL agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/notebook/dataGen.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/notebook/dataGen.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m path_number \u001b[39m=\u001b[39m \u001b[39m777\u001b[39m \u001b[39m# chose a path number in [0,n-1]\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/notebook/dataGen.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39marray(action_path)[path_number], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRL delta\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/notebook/dataGen.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(holding_gbm[path_number], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mClassic delta\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexei.ermochkine/Desktop/ml_project_2_deep_hedging/notebook/dataGen.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "path_number = 777 # chose a path number in [0,n-1]\n",
    "\n",
    "plt.plot(np.array(action_path)[path_number], label='RL delta')\n",
    "plt.plot(holding_gbm[path_number], label='Classic delta')\n",
    "plt.xlabel('')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
