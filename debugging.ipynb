{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Desktop/Repos/ml_project_2_deep_hedging/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from src.env import StockTradingEnv\n",
    "from src.agent import DDPG_Hedger\n",
    "from src.network import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/hypparams.json\", \"r\") as file:\n",
    "    hyp_params = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from copy import deepcopy\n",
    "from src.buffer import ExpReplay\n",
    "from collections import namedtuple\n",
    "from torch.distributions import Normal\n",
    "\n",
    "\n",
    "class DDPG_Hedger:\n",
    "    def __init__(\n",
    "        self,\n",
    "        Actor: nn.Module,\n",
    "        Critic_1: nn.Module,\n",
    "        Critic_2: nn.Module,\n",
    "        actor_lr: float,\n",
    "        critic_lr: float,\n",
    "        disc_rate: float = 1,\n",
    "        batch_size: int = 32,\n",
    "    ):\n",
    "\n",
    "        # params\n",
    "        self.gamma = disc_rate\n",
    "        self.tau = 0.01\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # experience replay related\n",
    "        self.transition = namedtuple(\n",
    "            \"Transition\",\n",
    "            (\"state\", \"action\", \"reward\", \"next_state\", \"done\"),\n",
    "        )\n",
    "        self.buffer = ExpReplay(10000, self.transition)\n",
    "\n",
    "        # define actor and critic ANN.\n",
    "        self.actor = Actor\n",
    "        self.critic_1 = Critic_1  # mean(cost)\n",
    "        self.critic_2 = Critic_2  # std(cost)\n",
    "\n",
    "        # loss function for critic\n",
    "        self.critic_loss = nn.MSELoss()\n",
    "\n",
    "        # define optimizer for Actor and Critic network\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "        self.critic_1_optimizer = optim.Adam(self.critic_1.parameters(), lr=critic_lr)\n",
    "        self.critic_2_optimizer = optim.Adam(self.critic_2.parameters(), lr=critic_lr)\n",
    "\n",
    "        # define target network needed for DDPG optimization\n",
    "        self.actor_target = deepcopy(self.actor)\n",
    "        self.critic_1_target = deepcopy(self.critic_1)\n",
    "        self.critic_2_target = deepcopy(self.critic_2)\n",
    "\n",
    "    def reset(self):\n",
    "        self.buffer.clear()\n",
    "\n",
    "    def store(self, *args):\n",
    "        self.buffer.store(*args)\n",
    "\n",
    "    def act(self, state: list, sigma: float = 0.2):\n",
    "        \"\"\"\n",
    "        We use policy function to find the deterministic action instead of distributions\n",
    "        which is parametrized by distribution parameters learned from the policy.\n",
    "\n",
    "        Here, state input prompts policy network to output a single or multiple-dim\n",
    "        actions.\n",
    "        :param state:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x = torch.tensor(state).to(torch.float64)\n",
    "        action = self.actor.forward(x)\n",
    "        noise = torch.normal(mean=torch.Tensor([0]),std=torch.Tensor([sigma]))\n",
    "        print(action, noise)\n",
    "        return (\n",
    "            torch.clip((action - 0.5) * 2 + noise, -state[0], 1.0 - state[0])\n",
    "            .detach()\n",
    "            .numpy()\n",
    "        )\n",
    "\n",
    "    def update(self, output=False):\n",
    "        # calculate return of all times in the episode\n",
    "        if self.buffer.len() < self.batch_size:\n",
    "            return\n",
    "\n",
    "        transitions = self.buffer.sample(self.batch_size)\n",
    "        batch = self.transition(*zip(*transitions))\n",
    "\n",
    "        # extract variables from sampled batch.\n",
    "        states = torch.tensor(batch.state)\n",
    "        actions = torch.tensor(batch.action)\n",
    "        rewards = torch.tensor(batch.reward)\n",
    "        dones = torch.tensor(batch.done).float()\n",
    "        next_states = torch.tensor(batch.next_state)\n",
    "\n",
    "        # compute Q_1 loss\n",
    "        Q_1 = self.critic_1(torch.hstack([states, actions]))\n",
    "        y_1 = rewards + self.gamma * (1 - dones) * self.critic_1_target(\n",
    "            torch.hstack([next_states, self.actor_target(next_states)]).detach()\n",
    "        )\n",
    "\n",
    "        critic_loss_1 = self.critic_loss(Q_1, y_1)\n",
    "        \n",
    "        # Optimize the critic Q_1\n",
    "        self.critic_1_optimizer.zero_grad()\n",
    "        critic_loss_1.backward()\n",
    "        self.critic_1_optimizer.step()\n",
    "\n",
    "        # compute Q_2 loss\n",
    "        Q_2 = self.critic_2(torch.hstack([states, actions]))\n",
    "        y_2 = (\n",
    "            rewards**2\n",
    "            + (self.gamma**2)\n",
    "            * (1 - dones)\n",
    "            * self.critic_2_target(\n",
    "                torch.hstack([next_states, self.actor_target(next_states)]).detach()\n",
    "            )\n",
    "            + 2\n",
    "            * self.gamma\n",
    "            * rewards\n",
    "            * self.critic_1_target(\n",
    "                torch.hstack([next_states, self.actor_target(next_states)]).detach()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        critic_loss_2 = self.critic_loss(Q_2, y_2)\n",
    "        \n",
    "        # Optimize the critic Q_2\n",
    "        self.critic_2_optimizer.zero_grad()\n",
    "        critic_loss_2.backward()\n",
    "        self.critic_2_optimizer.step()\n",
    "\n",
    "\n",
    "        # Get actor loss\n",
    "        state_action = torch.hstack([states, self.actor(states)])\n",
    "        cost_variance = (\n",
    "            self.critic_2(state_action)\n",
    "            - self.critic_1(state_action) ** 2\n",
    "        )\n",
    "        #print(self.critic_1(state_action)[:3], self.critic_2(state_action)[:3])\n",
    "        actor_loss = (\n",
    "            self.critic_1(state_action)\n",
    "            + 1.5 * torch.sqrt(torch.where(cost_variance < 0, 0, cost_variance))\n",
    "        ).mean()\n",
    "\n",
    "        # Optimize the actor\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        print(critic_loss_1, critic_loss_2, actor_loss)\n",
    "\n",
    "        if output:\n",
    "            return actor_loss.detach().item()\n",
    "\n",
    "    def polyak_update(self):\n",
    "        # Update the frozen target models\n",
    "        for trg_param, src_param in zip(\n",
    "            list(self.critic_1_target.parameters()), list(self.critic_1.parameters())\n",
    "        ):\n",
    "            trg_param = trg_param * (1.0 - self.tau) + src_param * self.tau\n",
    "\n",
    "        # Update the frozen target models\n",
    "        for trg_param, src_param in zip(\n",
    "            list(self.critic_2_target.parameters()), list(self.critic_2.parameters())\n",
    "        ):\n",
    "            trg_param = trg_param * (1.0 - self.tau) + src_param * self.tau\n",
    "\n",
    "\n",
    "        for trg_param, src_param in zip(\n",
    "            list(self.actor_target.parameters()), list(self.actor.parameters())\n",
    "        ):\n",
    "            trg_param = trg_param * (1.0 - self.tau) + src_param * self.tau\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save(self.critic.state_dict(), filename + \"_critic\")\n",
    "        torch.save(self.critic_optimizer.state_dict(), filename + \"_critic_hyp_params\")\n",
    "\n",
    "        torch.save(self.actor.state_dict(), filename + \"_actor\")\n",
    "        torch.save(self.actor_optimizer.state_dict(), filename + \"_actor_hyp_params\")\n",
    "\n",
    "    def load(self, filename):\n",
    "        self.critic.load_state_dict(torch.load(filename + \"_critic\"))\n",
    "        self.critic_optimizer.load_state_dict(\n",
    "            torch.load(filename + \"_critic_hyp_params\")\n",
    "        )\n",
    "\n",
    "        self.actor.load_state_dict(torch.load(filename + \"_actor\"))\n",
    "        self.actor_optimizer.load_state_dict(torch.load(filename + \"_actor_hyp_params\"))\n",
    "\n",
    "        # define target network needed for DDPG optimization\n",
    "        self.actor_target = deepcopy(self.actor)\n",
    "        self.critic_target = deepcopy(self.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "N_EPISODE = 1\n",
    "\n",
    "env = StockTradingEnv(reset_path=True)\n",
    "\n",
    "nHidden = hyp_params[\"hidden_dim\"]\n",
    "actor_lr = 10 ** hyp_params[\"actor_lr\"]\n",
    "critic_lr = 10 ** hyp_params[\"critic_lr\"]\n",
    "trg_update = hyp_params[\"polyak_update_freq\"]\n",
    "nState, nAction = env.observation_space.shape[0], env.action_space.shape[0]  # 3, 1\n",
    "\n",
    "actor_lr\n",
    "\n",
    "actor = MLP(nState, nHidden, nAction, \"Sigmoid\")\n",
    "qnet_1 = MLP(nState + nAction, nHidden, nAction, \"\")\n",
    "qnet_2 = MLP(nState + nAction, nHidden, nAction, \"\")\n",
    "agent = DDPG_Hedger(actor, qnet_1, qnet_2, actor_lr, critic_lr, 1, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "------- step 1 action:\n",
      "tensor([0.3838], grad_fn=<SigmoidBackward0>) tensor([-0.5296])\n",
      "1\n",
      "------- step 2 action:\n",
      "tensor([0.3839], grad_fn=<SigmoidBackward0>) tensor([0.6695])\n",
      "1\n",
      "------- step 3 action:\n",
      "tensor([0.3845], grad_fn=<SigmoidBackward0>) tensor([-0.4908])\n",
      "1\n",
      "------- step 4 action:\n",
      "tensor([0.3840], grad_fn=<SigmoidBackward0>) tensor([0.1980])\n",
      "1\n",
      "------- step 5 action:\n",
      "tensor([0.3841], grad_fn=<SigmoidBackward0>) tensor([0.4619])\n",
      "1\n",
      "------- step 6 action:\n",
      "tensor([0.3845], grad_fn=<SigmoidBackward0>) tensor([0.9056])\n",
      "1\n",
      "------- step 7 action:\n",
      "tensor([0.3855], grad_fn=<SigmoidBackward0>) tensor([0.3452])\n",
      "1\n",
      "------- step 8 action:\n",
      "tensor([0.3857], grad_fn=<SigmoidBackward0>) tensor([-0.0576])\n",
      "1\n",
      "------- step 9 action:\n",
      "tensor([0.3856], grad_fn=<SigmoidBackward0>) tensor([-1.1464])\n",
      "1\n",
      "------- step 10 action:\n",
      "tensor([0.3849], grad_fn=<SigmoidBackward0>) tensor([-1.9654])\n",
      "1\n",
      "------- step 11 action:\n",
      "tensor([0.3851], grad_fn=<SigmoidBackward0>) tensor([0.9580])\n",
      "1\n",
      "------- step 12 action:\n",
      "tensor([0.3862], grad_fn=<SigmoidBackward0>) tensor([-1.0983])\n",
      "1\n",
      "------- step 13 action:\n",
      "tensor([0.3855], grad_fn=<SigmoidBackward0>) tensor([-1.2722])\n",
      "1\n",
      "------- step 14 action:\n",
      "tensor([0.3855], grad_fn=<SigmoidBackward0>) tensor([0.0034])\n",
      "1\n",
      "------- step 15 action:\n",
      "tensor([0.3855], grad_fn=<SigmoidBackward0>) tensor([-0.0804])\n",
      "1\n",
      "------- step 16 action:\n",
      "tensor([0.3853], grad_fn=<SigmoidBackward0>) tensor([-1.5840])\n",
      "tensor(2.4598, grad_fn=<MseLossBackward0>) tensor(16.2630, grad_fn=<MseLossBackward0>) tensor(-1.6132, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 17 action:\n",
      "tensor([0.8222], grad_fn=<SigmoidBackward0>) tensor([0.1983])\n",
      "tensor(3.1513, grad_fn=<MseLossBackward0>) tensor(5.4417, grad_fn=<MseLossBackward0>) tensor(0.8263, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 18 action:\n",
      "tensor([0.9378], grad_fn=<SigmoidBackward0>) tensor([1.2552])\n",
      "tensor(2.6945, grad_fn=<MseLossBackward0>) tensor(10.0825, grad_fn=<MseLossBackward0>) tensor(2.1391, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 19 action:\n",
      "tensor([0.9599], grad_fn=<SigmoidBackward0>) tensor([-0.0412])\n",
      "tensor(2.1283, grad_fn=<MseLossBackward0>) tensor(11.7962, grad_fn=<MseLossBackward0>) tensor(2.6348, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 20 action:\n",
      "tensor([0.9708], grad_fn=<SigmoidBackward0>) tensor([0.4385])\n",
      "tensor(2.4331, grad_fn=<MseLossBackward0>) tensor(9.9275, grad_fn=<MseLossBackward0>) tensor(2.8107, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 21 action:\n",
      "tensor([0.9773], grad_fn=<SigmoidBackward0>) tensor([0.4701])\n",
      "tensor(3.0258, grad_fn=<MseLossBackward0>) tensor(13.2535, grad_fn=<MseLossBackward0>) tensor(2.7995, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 22 action:\n",
      "tensor([0.9816], grad_fn=<SigmoidBackward0>) tensor([0.0458])\n",
      "tensor(3.2144, grad_fn=<MseLossBackward0>) tensor(28.7239, grad_fn=<MseLossBackward0>) tensor(2.7386, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 23 action:\n",
      "tensor([0.9846], grad_fn=<SigmoidBackward0>) tensor([-1.9379])\n",
      "tensor(3.5385, grad_fn=<MseLossBackward0>) tensor(26.4769, grad_fn=<MseLossBackward0>) tensor(2.5991, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 24 action:\n",
      "tensor([0.9857], grad_fn=<SigmoidBackward0>) tensor([2.0916])\n",
      "tensor(2.3820, grad_fn=<MseLossBackward0>) tensor(11.6074, grad_fn=<MseLossBackward0>) tensor(2.3825, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 25 action:\n",
      "tensor([0.9861], grad_fn=<SigmoidBackward0>) tensor([-0.2195])\n",
      "tensor(3.4306, grad_fn=<MseLossBackward0>) tensor(25.3281, grad_fn=<MseLossBackward0>) tensor(2.2556, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 26 action:\n",
      "tensor([0.9860], grad_fn=<SigmoidBackward0>) tensor([0.2674])\n",
      "tensor(4.8693, grad_fn=<MseLossBackward0>) tensor(29.7858, grad_fn=<MseLossBackward0>) tensor(2.2521, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 27 action:\n",
      "tensor([0.9877], grad_fn=<SigmoidBackward0>) tensor([-0.3842])\n",
      "tensor(2.8445, grad_fn=<MseLossBackward0>) tensor(27.0681, grad_fn=<MseLossBackward0>) tensor(2.2056, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 28 action:\n",
      "tensor([0.9893], grad_fn=<SigmoidBackward0>) tensor([-1.3736])\n",
      "tensor(3.0740, grad_fn=<MseLossBackward0>) tensor(28.4231, grad_fn=<MseLossBackward0>) tensor(2.1423, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 29 action:\n",
      "tensor([0.9908], grad_fn=<SigmoidBackward0>) tensor([-1.0745])\n",
      "tensor(4.0939, grad_fn=<MseLossBackward0>) tensor(29.0937, grad_fn=<MseLossBackward0>) tensor(2.1731, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 30 action:\n",
      "tensor([0.9918], grad_fn=<SigmoidBackward0>) tensor([-1.5809])\n",
      "tensor(3.9501, grad_fn=<MseLossBackward0>) tensor(28.5498, grad_fn=<MseLossBackward0>) tensor(2.1999, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 31 action:\n",
      "tensor([0.9925], grad_fn=<SigmoidBackward0>) tensor([0.5738])\n",
      "tensor(2.6516, grad_fn=<MseLossBackward0>) tensor(25.2443, grad_fn=<MseLossBackward0>) tensor(2.2009, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 32 action:\n",
      "tensor([0.9925], grad_fn=<SigmoidBackward0>) tensor([-0.0343])\n",
      "tensor(2.2148, grad_fn=<MseLossBackward0>) tensor(10.9448, grad_fn=<MseLossBackward0>) tensor(2.1674, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 33 action:\n",
      "tensor([0.9918], grad_fn=<SigmoidBackward0>) tensor([-0.9067])\n",
      "tensor(1.7496, grad_fn=<MseLossBackward0>) tensor(8.4298, grad_fn=<MseLossBackward0>) tensor(2.1034, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 34 action:\n",
      "tensor([0.9904], grad_fn=<SigmoidBackward0>) tensor([0.6441])\n",
      "tensor(2.5590, grad_fn=<MseLossBackward0>) tensor(9.2970, grad_fn=<MseLossBackward0>) tensor(2.0450, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 35 action:\n",
      "tensor([0.9880], grad_fn=<SigmoidBackward0>) tensor([-1.7936])\n",
      "tensor(2.1480, grad_fn=<MseLossBackward0>) tensor(28.0214, grad_fn=<MseLossBackward0>) tensor(1.9804, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 36 action:\n",
      "tensor([0.9841], grad_fn=<SigmoidBackward0>) tensor([0.1409])\n",
      "tensor(2.1936, grad_fn=<MseLossBackward0>) tensor(25.3643, grad_fn=<MseLossBackward0>) tensor(1.9059, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 37 action:\n",
      "tensor([0.9787], grad_fn=<SigmoidBackward0>) tensor([0.5129])\n",
      "tensor(2.5882, grad_fn=<MseLossBackward0>) tensor(14.2271, grad_fn=<MseLossBackward0>) tensor(1.8787, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 38 action:\n",
      "tensor([0.9707], grad_fn=<SigmoidBackward0>) tensor([0.1166])\n",
      "tensor(2.6403, grad_fn=<MseLossBackward0>) tensor(10.4558, grad_fn=<MseLossBackward0>) tensor(1.9074, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 39 action:\n",
      "tensor([0.9583], grad_fn=<SigmoidBackward0>) tensor([1.0030])\n",
      "tensor(2.9293, grad_fn=<MseLossBackward0>) tensor(29.0861, grad_fn=<MseLossBackward0>) tensor(1.9656, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 40 action:\n",
      "tensor([0.9399], grad_fn=<SigmoidBackward0>) tensor([1.7270])\n",
      "tensor(3.8486, grad_fn=<MseLossBackward0>) tensor(33.3856, grad_fn=<MseLossBackward0>) tensor(2.0593, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 41 action:\n",
      "tensor([0.9123], grad_fn=<SigmoidBackward0>) tensor([0.3079])\n",
      "tensor(3.0163, grad_fn=<MseLossBackward0>) tensor(25.2876, grad_fn=<MseLossBackward0>) tensor(2.1194, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 42 action:\n",
      "tensor([0.8708], grad_fn=<SigmoidBackward0>) tensor([0.1580])\n",
      "tensor(2.7528, grad_fn=<MseLossBackward0>) tensor(12.3979, grad_fn=<MseLossBackward0>) tensor(2.2123, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 43 action:\n",
      "tensor([0.8090], grad_fn=<SigmoidBackward0>) tensor([-0.3270])\n",
      "tensor(2.4372, grad_fn=<MseLossBackward0>) tensor(11.9604, grad_fn=<MseLossBackward0>) tensor(2.2614, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 44 action:\n",
      "tensor([0.7200], grad_fn=<SigmoidBackward0>) tensor([0.2716])\n",
      "tensor(2.7910, grad_fn=<MseLossBackward0>) tensor(21.6461, grad_fn=<MseLossBackward0>) tensor(2.2454, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 45 action:\n",
      "tensor([0.5997], grad_fn=<SigmoidBackward0>) tensor([0.8335])\n",
      "tensor(1.8284, grad_fn=<MseLossBackward0>) tensor(7.1564, grad_fn=<MseLossBackward0>) tensor(2.2117, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 46 action:\n",
      "tensor([0.4567], grad_fn=<SigmoidBackward0>) tensor([0.5404])\n",
      "tensor(2.3029, grad_fn=<MseLossBackward0>) tensor(5.9169, grad_fn=<MseLossBackward0>) tensor(2.2058, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 47 action:\n",
      "tensor([0.3096], grad_fn=<SigmoidBackward0>) tensor([-0.0913])\n",
      "tensor(1.4493, grad_fn=<MseLossBackward0>) tensor(5.9590, grad_fn=<MseLossBackward0>) tensor(2.1671, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 48 action:\n",
      "tensor([0.1905], grad_fn=<SigmoidBackward0>) tensor([0.0338])\n",
      "tensor(2.0630, grad_fn=<MseLossBackward0>) tensor(7.2981, grad_fn=<MseLossBackward0>) tensor(2.1141, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 49 action:\n",
      "tensor([0.1098], grad_fn=<SigmoidBackward0>) tensor([-0.7675])\n",
      "tensor(2.5799, grad_fn=<MseLossBackward0>) tensor(23.2242, grad_fn=<MseLossBackward0>) tensor(2.0057, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 50 action:\n",
      "tensor([0.0621], grad_fn=<SigmoidBackward0>) tensor([1.5029])\n",
      "tensor(2.2657, grad_fn=<MseLossBackward0>) tensor(13.9409, grad_fn=<MseLossBackward0>) tensor(1.8774, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 51 action:\n",
      "tensor([0.0366], grad_fn=<SigmoidBackward0>) tensor([-0.2504])\n",
      "tensor(1.6126, grad_fn=<MseLossBackward0>) tensor(5.9692, grad_fn=<MseLossBackward0>) tensor(1.7912, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 52 action:\n",
      "tensor([0.0223], grad_fn=<SigmoidBackward0>) tensor([0.7935])\n",
      "tensor(2.9964, grad_fn=<MseLossBackward0>) tensor(24.3533, grad_fn=<MseLossBackward0>) tensor(1.7269, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 53 action:\n",
      "tensor([0.0141], grad_fn=<SigmoidBackward0>) tensor([1.0694])\n",
      "tensor(2.0758, grad_fn=<MseLossBackward0>) tensor(7.6794, grad_fn=<MseLossBackward0>) tensor(1.7175, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 54 action:\n",
      "tensor([0.0092], grad_fn=<SigmoidBackward0>) tensor([0.8647])\n",
      "tensor(2.3428, grad_fn=<MseLossBackward0>) tensor(7.6827, grad_fn=<MseLossBackward0>) tensor(1.6737, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 55 action:\n",
      "tensor([0.0063], grad_fn=<SigmoidBackward0>) tensor([-0.2911])\n",
      "tensor(2.3780, grad_fn=<MseLossBackward0>) tensor(12.9071, grad_fn=<MseLossBackward0>) tensor(1.6687, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 56 action:\n",
      "tensor([0.0045], grad_fn=<SigmoidBackward0>) tensor([0.4103])\n",
      "tensor(1.0093, grad_fn=<MseLossBackward0>) tensor(4.0868, grad_fn=<MseLossBackward0>) tensor(1.6383, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 57 action:\n",
      "tensor([0.0033], grad_fn=<SigmoidBackward0>) tensor([-0.6160])\n",
      "tensor(2.5261, grad_fn=<MseLossBackward0>) tensor(15.5919, grad_fn=<MseLossBackward0>) tensor(1.6728, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 58 action:\n",
      "tensor([0.0024], grad_fn=<SigmoidBackward0>) tensor([-0.5122])\n",
      "tensor(1.6347, grad_fn=<MseLossBackward0>) tensor(4.2863, grad_fn=<MseLossBackward0>) tensor(1.7157, grad_fn=<MeanBackward0>)\n",
      "1\n",
      "------- step 59 action:\n",
      "tensor([0.0018], grad_fn=<SigmoidBackward0>) tensor([0.4487])\n",
      "tensor(4.1147, grad_fn=<MseLossBackward0>) tensor(39.6945, grad_fn=<MseLossBackward0>) tensor(1.7720, grad_fn=<MeanBackward0>)\n",
      "Episode 0 Reward: [54.61153265]\n"
     ]
    }
   ],
   "source": [
    "target_rewards = []\n",
    "noise_std = 1\n",
    "\n",
    "for episode in range(N_EPISODE):\n",
    "    # reset state\n",
    "    state = env.reset()  # s_0\n",
    "    ep_tot_reward = 0\n",
    "\n",
    "    if episode > N_EPISODE - 30:\n",
    "        noise_std = 0.0001\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        # take action given state\n",
    "        print(noise_std)\n",
    "        print(f'------- step {i+1} action:')\n",
    "        action = agent.act(state, noise_std)\n",
    "        \n",
    "        # take next step of the environment\n",
    "        next_state, reward, done = env.step(action)\n",
    "\n",
    "        # record interaction between environment and the agent\n",
    "        agent.store(state, action, reward, next_state, done)\n",
    "\n",
    "        ep_tot_reward -= reward\n",
    "        state = next_state\n",
    "        \n",
    "        agent.update()\n",
    "\n",
    "        i +=1 \n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "    print(f\"Episode {episode} Reward: {ep_tot_reward}\")\n",
    "    # store total rewards after some training is done\n",
    "    # we only consider alst 10 total rewards as a quantity to minimize\n",
    "    if episode > N_EPISODE - 30:\n",
    "        target_rewards.append(ep_tot_reward)\n",
    "\n",
    "    if episode % trg_update == 0:  # update target network\n",
    "        agent.polyak_update()\n",
    "\n",
    "#print(np.mean(target_rewards))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6170])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=torch.Tensor([0]),std=torch.Tensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5899])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = 1\n",
    "torch.normal(mean=torch.Tensor([0]),std=torch.Tensor([sigma]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor\n",
      "Parameter containing:\n",
      "tensor([[-0.3552, -0.4805,  0.3367],\n",
      "        [-0.0299, -0.0076, -0.2759],\n",
      "        [ 0.2599, -0.5416, -0.5670],\n",
      "        [-0.5094, -0.0040,  0.6235],\n",
      "        [-0.1893, -0.0390, -0.2158],\n",
      "        [-0.5011,  0.5183,  0.6193],\n",
      "        [ 0.5510, -0.0094, -0.5343],\n",
      "        [-0.2291, -0.1014,  0.2488],\n",
      "        [ 0.1784,  0.5880, -0.1074],\n",
      "        [-0.4285,  0.2169, -0.6727],\n",
      "        [ 0.3106,  0.4529,  0.3806],\n",
      "        [ 0.2937,  0.4808, -0.2007],\n",
      "        [ 0.4296, -0.2141,  0.0259]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3141, -0.4637,  0.4545, -0.1267, -0.2552,  0.0329,  0.2607, -0.4837,\n",
      "        -0.3835, -0.0641, -0.3224,  0.1753,  0.2736], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.7990, 1.0038, 0.8314, 0.8326, 1.2060, 1.1693, 0.8005, 1.1530, 1.2068,\n",
      "        0.8516, 1.0226, 0.8343, 0.7625], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2011, -0.0007,  0.1688,  0.1939, -0.2056,  0.1698,  0.1999,  0.0382,\n",
      "         0.1996,  0.1364,  0.0277,  0.2148,  0.2361], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.0744e-01, -6.4374e-02,  7.7913e-02, -3.4183e-01, -2.9950e-02,\n",
      "          7.4279e-02, -4.6219e-02,  5.0358e-02,  6.2275e-02, -3.0489e-01,\n",
      "          2.8028e-01, -6.1854e-03, -1.5295e-01],\n",
      "        [-2.3529e-01,  6.2823e-02, -2.6793e-01,  1.8938e-01,  2.1412e-01,\n",
      "         -2.2424e-04,  3.0385e-02, -2.3165e-01, -1.9131e-02,  2.3427e-02,\n",
      "         -1.2410e-01, -7.8504e-02,  2.4386e-01],\n",
      "        [-8.5033e-02, -2.9885e-01, -4.0976e-01, -1.0875e-01, -6.4537e-02,\n",
      "          2.3198e-01,  3.9731e-02,  3.5182e-01,  3.2032e-01, -1.1825e-01,\n",
      "          4.7517e-01, -3.2421e-01, -3.0798e-01],\n",
      "        [-1.0142e-02,  1.8320e-01,  2.3317e-01,  2.3488e-01, -2.6729e-02,\n",
      "         -1.2620e-01,  2.0141e-01,  1.2098e-02, -8.6744e-02, -1.3981e-01,\n",
      "          1.6517e-01, -1.8185e-01,  1.5781e-01],\n",
      "        [-7.8848e-02,  1.7942e-01,  2.6317e-02,  2.7073e-01,  8.0773e-02,\n",
      "         -4.7653e-02, -8.4183e-03, -2.6202e-01, -2.5653e-01, -6.6367e-02,\n",
      "          4.8381e-02,  2.6505e-01, -2.3359e-02],\n",
      "        [-2.8954e-02, -1.3628e-01,  3.8365e-01,  4.0308e-02,  2.9119e-01,\n",
      "          9.2626e-02,  1.8643e-01,  1.2712e-01, -1.0271e-01,  1.1475e-03,\n",
      "         -3.5031e-01,  3.7868e-02,  1.0065e-01],\n",
      "        [-2.6838e-01, -5.8034e-02, -8.4423e-02, -1.8345e-01, -4.3437e-01,\n",
      "          2.8585e-01,  4.1458e-02,  3.2647e-01,  4.1639e-02, -1.7103e-01,\n",
      "          4.1265e-01,  3.9805e-02, -1.5638e-02],\n",
      "        [-2.3371e-02,  4.6169e-02,  9.0607e-02,  6.7392e-02,  1.5614e-01,\n",
      "         -2.4618e-01, -1.1562e-01, -2.1404e-01, -1.2535e-01,  4.0328e-01,\n",
      "          5.4886e-02,  8.8939e-02,  2.9256e-01],\n",
      "        [-1.4843e-01,  8.4953e-02, -1.7207e-02, -3.9467e-02,  2.3117e-01,\n",
      "         -6.3224e-02, -6.9853e-02,  3.2872e-02, -3.0283e-02, -1.7233e-02,\n",
      "         -1.1384e-01,  5.7488e-02, -1.4019e-01],\n",
      "        [-1.4784e-01,  2.6206e-01,  1.0262e-01, -9.6887e-02,  1.1292e-01,\n",
      "         -9.2453e-02,  1.8495e-01, -2.0671e-01,  1.1311e-01, -2.5211e-01,\n",
      "         -2.0850e-01,  8.2546e-03,  1.0860e-01],\n",
      "        [ 3.0884e-02,  1.1681e-01, -3.4032e-02, -6.2649e-02,  3.7452e-01,\n",
      "         -1.9325e-01,  3.2209e-01, -1.9091e-01, -6.1722e-02,  2.2625e-01,\n",
      "         -8.0013e-02,  2.5221e-01, -4.1468e-02],\n",
      "        [ 1.0789e-01,  2.5535e-01,  1.4671e-01,  7.7408e-02,  3.1645e-01,\n",
      "         -2.7950e-02,  1.6666e-01,  9.4261e-03, -9.3551e-02,  2.6918e-01,\n",
      "         -2.9246e-01,  1.8626e-01,  3.9046e-02],\n",
      "        [ 5.1888e-02, -1.9993e-01, -2.3668e-01, -1.2455e-01,  1.6165e-01,\n",
      "         -2.1741e-01, -1.9046e-01, -8.0225e-02,  4.3318e-02,  9.1162e-02,\n",
      "         -5.1372e-02, -1.2034e-01,  3.7305e-02],\n",
      "        [-2.3291e-01, -1.3161e-01,  2.2298e-02, -3.5271e-02, -6.9321e-02,\n",
      "          1.2510e-01, -1.7723e-01,  2.0664e-01, -2.5044e-01,  2.3498e-01,\n",
      "         -2.6671e-01,  1.2315e-01,  1.0479e-01],\n",
      "        [ 1.5729e-01,  2.9571e-01,  1.3058e-01, -9.6093e-02,  4.0502e-01,\n",
      "         -1.6322e-01, -2.4523e-02,  1.0800e-02, -1.3642e-01, -7.9367e-02,\n",
      "         -4.0481e-02,  3.8514e-01,  3.5829e-01],\n",
      "        [-2.0181e-01, -3.8199e-01, -1.6226e-01, -1.7763e-01, -2.4346e-01,\n",
      "          1.7546e-01, -3.4133e-01,  4.2008e-02,  3.0994e-01, -2.8873e-01,\n",
      "          1.7367e-01, -1.7688e-03, -4.1957e-01],\n",
      "        [-6.0580e-02,  2.6306e-01,  3.8165e-02,  1.3537e-01,  7.7672e-02,\n",
      "         -1.7541e-01, -4.0521e-02, -1.8789e-01, -3.4302e-01,  2.8079e-01,\n",
      "         -8.5045e-03,  2.1465e-01,  3.7819e-01],\n",
      "        [-4.5494e-01, -6.6133e-01, -6.9283e-01,  7.0604e-01, -8.3385e-01,\n",
      "          5.9235e-01, -6.9967e-01, -9.0295e-01,  8.5467e-01, -8.0496e-01,\n",
      "          8.8662e-01,  8.1220e-01, -5.7351e-01],\n",
      "        [ 2.4073e-01,  5.3207e-02,  6.9039e-02,  1.9061e-01,  2.8689e-02,\n",
      "         -5.5671e-02, -2.2710e-01,  2.2498e-01, -6.0072e-02,  2.3303e-02,\n",
      "         -1.6341e-01,  1.8025e-01,  2.0678e-01],\n",
      "        [ 1.1110e-02, -1.0214e-01, -3.5133e-01, -3.0572e-02, -2.5194e-01,\n",
      "          4.4473e-01, -3.8449e-01,  1.9527e-01,  4.0026e-01, -2.4409e-01,\n",
      "          2.5821e-01, -5.4519e-02, -9.5143e-02],\n",
      "        [-2.6222e-02,  1.5025e-01, -1.7533e-02,  1.6185e-01,  3.0360e-01,\n",
      "         -2.3792e-01,  2.1961e-01, -3.1563e-01, -1.8784e-01,  5.8703e-03,\n",
      "         -7.4142e-02,  2.3753e-03, -6.0666e-02],\n",
      "        [-4.4654e-03, -1.3687e-01,  2.7077e-01, -5.4234e-02,  3.7434e-02,\n",
      "          5.8877e-02,  1.6537e-01, -2.1982e-01, -1.0375e-01, -1.8415e-01,\n",
      "         -3.5167e-02,  5.2209e-02, -1.1350e-01],\n",
      "        [ 1.6586e-01,  2.0283e-01,  1.5454e-01, -1.2234e-01, -2.7694e-01,\n",
      "          2.6194e-01, -1.3820e-01, -8.2506e-02,  1.7946e-01, -1.0597e-01,\n",
      "         -4.2997e-03, -2.1909e-01, -3.1957e-01],\n",
      "        [ 1.5476e-01, -1.1388e-01, -3.2042e-01, -7.1236e-02,  5.6397e-03,\n",
      "          2.6632e-01,  3.7768e-02,  3.8738e-01,  1.2416e-02,  1.2834e-01,\n",
      "          1.9194e-01, -1.7251e-01, -3.2324e-01],\n",
      "        [ 2.5164e-03,  1.8268e-01,  6.5084e-02,  2.7338e-01,  1.4498e-01,\n",
      "         -1.2287e-01,  5.5634e-02,  2.4713e-01, -2.1639e-01, -5.7834e-02,\n",
      "          4.3603e-04,  2.2228e-01,  2.4325e-01],\n",
      "        [ 4.6445e-02,  2.5083e-02,  3.0979e-02,  1.3073e-01,  1.7784e-01,\n",
      "          1.7184e-01,  1.7063e-01,  1.3408e-01, -2.3507e-01, -1.5423e-01,\n",
      "         -1.2829e-02,  1.9224e-01,  2.5741e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2148,  0.2685,  0.0699,  0.1106, -0.2797, -0.3095,  0.0824, -0.3951,\n",
      "         0.1357,  0.0059, -0.4428,  0.0744,  0.0972,  0.0693, -0.0011,  0.4545,\n",
      "        -0.4054,  0.9179, -0.2721,  0.2952, -0.2098, -0.2433,  0.1321,  0.2969,\n",
      "         0.0747, -0.0363], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.2481, 1.2411, 1.2412, 0.7678, 0.8701, 1.2218, 1.0542, 1.2442, 1.2414,\n",
      "        0.7790, 1.1367, 0.9385, 1.2413, 1.1028, 1.2295, 1.2364, 1.0405, 1.3156,\n",
      "        1.2411, 1.2481, 0.8416, 0.7737, 0.9518, 1.2411, 0.7657, 1.0791],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2382, -0.2423,  0.2414,  0.2356, -0.1281, -0.2417,  0.2396, -0.2423,\n",
      "        -0.2423,  0.2254, -0.2436, -0.2355, -0.2423, -0.1072, -0.2419,  0.2407,\n",
      "        -0.2391, -0.2422, -0.2423,  0.2418, -0.2341,  0.2304, -0.2452,  0.2423,\n",
      "         0.2374, -0.0855], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2676,  0.3827, -0.3454,  0.1149, -0.1917,  0.3709, -0.2057,  0.3840,\n",
      "          0.3576,  0.1679,  0.2868,  0.0921,  0.3635,  0.2247,  0.3281, -0.3546,\n",
      "          0.2539,  0.3711,  0.3952, -0.4282, -0.0161,  0.1535,  0.0746, -0.3533,\n",
      "          0.0799,  0.2223]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3244], requires_grad=True)\n",
      "Critic_1\n",
      "Parameter containing:\n",
      "tensor([[ 0.4629,  0.5622, -0.0740, -0.0799],\n",
      "        [ 0.2614,  0.0365,  0.4006, -0.0756],\n",
      "        [ 0.1066, -0.1545,  0.0387,  0.1081],\n",
      "        [-0.3214,  0.1398, -0.3292, -0.1746],\n",
      "        [ 0.2782, -0.1706, -0.2417,  0.4776],\n",
      "        [-0.1159,  0.3034,  0.1157, -0.3826],\n",
      "        [-0.2612,  0.2397,  0.3038, -0.1013],\n",
      "        [-0.2815,  0.0217,  0.4126, -0.4933],\n",
      "        [ 0.0917,  0.4892,  0.4093,  0.4590],\n",
      "        [ 0.1507, -0.4764,  0.2757, -0.4171],\n",
      "        [ 0.3257, -0.4944, -0.3441, -0.4351],\n",
      "        [-0.1792,  0.1559,  0.1819,  0.0082],\n",
      "        [-0.4003,  0.0532, -0.3462, -0.0427]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.5397,  0.3643, -0.2740, -0.2995, -0.1196,  0.2210,  0.2105,  0.2964,\n",
      "        -0.2971, -0.4458, -0.3294,  0.4890, -0.0309], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.1230, 0.9354, 0.9687, 1.1069, 1.0135, 1.0061, 0.9265, 0.9406, 1.1058,\n",
      "        1.0610, 0.9524, 0.9637, 1.0993], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1329, -0.0606,  0.0347, -0.1145, -0.0177,  0.0274, -0.0318,  0.0510,\n",
      "         0.1088, -0.0635,  0.0464,  0.0409, -0.0994], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0151,  0.1929, -0.2281, -0.1604,  0.1153, -0.2736, -0.2867, -0.0736,\n",
      "          0.1192,  0.3106,  0.1246,  0.1082,  0.1031],\n",
      "        [-0.0514,  0.0684, -0.3976, -0.2340, -0.1523,  0.3515,  0.4244, -0.1419,\n",
      "          0.3875, -0.1933, -0.1376,  0.2438, -0.3092],\n",
      "        [-0.3065,  0.1480, -0.0770, -0.0599, -0.0060,  0.1662,  0.1053, -0.0939,\n",
      "         -0.0192,  0.1822,  0.0095,  0.1058,  0.1370],\n",
      "        [-0.0276, -0.3903, -0.0640, -0.0911,  0.2610, -0.2496, -0.1257,  0.3404,\n",
      "         -0.3421,  0.2221, -0.0915, -0.2172, -0.0526],\n",
      "        [-0.4333, -0.1995,  0.1619, -0.0132,  0.1078, -0.3476, -0.1123, -0.0499,\n",
      "          0.0946,  0.2488,  0.0937, -0.3430, -0.0850],\n",
      "        [ 0.1087, -0.1006, -0.1746, -0.1726, -0.2140, -0.1697,  0.1707,  0.0857,\n",
      "          0.1082, -0.1214, -0.2171,  0.0181,  0.0754],\n",
      "        [-0.2433, -0.0159,  0.3532,  0.2214, -0.1296, -0.2499, -0.1860,  0.3469,\n",
      "          0.0768, -0.0896, -0.0689, -0.3264,  0.2161],\n",
      "        [ 0.0681,  0.1631,  0.0210,  0.2251,  0.0225, -0.0315,  0.2449,  0.1565,\n",
      "         -0.2432, -0.2679,  0.0047,  0.1242, -0.0388],\n",
      "        [ 0.1016,  0.1274,  0.1581,  0.1464,  0.0833, -0.2728,  0.0467,  0.2455,\n",
      "          0.0039, -0.2043, -0.2256,  0.2513, -0.0875],\n",
      "        [-0.0904,  0.0491,  0.0607, -0.1251,  0.2315, -0.0020, -0.0620, -0.2397,\n",
      "         -0.1212, -0.1094,  0.0887,  0.1782, -0.1235],\n",
      "        [ 0.2208,  0.2851, -0.2930,  0.1418,  0.0911, -0.0764, -0.0322, -0.0591,\n",
      "          0.2832,  0.0451, -0.3122,  0.2955, -0.1029],\n",
      "        [-0.2565,  0.1301,  0.1841, -0.0240,  0.0888,  0.0989, -0.2182,  0.2100,\n",
      "         -0.3447, -0.0147, -0.1044,  0.1341, -0.0658],\n",
      "        [ 0.0946, -0.2465,  0.1007, -0.1191,  0.1174, -0.0839, -0.0456, -0.2305,\n",
      "         -0.2430,  0.2346, -0.0662, -0.1170, -0.1215],\n",
      "        [-0.0845,  0.3005,  0.0184,  0.0211,  0.0384, -0.1332, -0.0315,  0.1842,\n",
      "          0.2963, -0.0823, -0.1408,  0.1718, -0.0329],\n",
      "        [-0.0147,  0.1191,  0.1992,  0.0412,  0.2704,  0.0307, -0.1182,  0.1093,\n",
      "         -0.0060,  0.0945, -0.1779, -0.2354,  0.1310],\n",
      "        [-0.2439, -0.2944, -0.1989,  0.0696, -0.1506, -0.0717, -0.0250,  0.1155,\n",
      "          0.2340,  0.2667, -0.1254,  0.1816, -0.1749],\n",
      "        [-0.1065, -0.0259,  0.1498,  0.0856, -0.2810,  0.3006, -0.0526, -0.2876,\n",
      "          0.2348, -0.2128, -0.1362,  0.2287, -0.1081],\n",
      "        [ 0.0642,  0.2344,  0.1627,  0.1450,  0.2206,  0.0763, -0.2758,  0.0769,\n",
      "          0.1997, -0.0059,  0.0975, -0.1341, -0.1448],\n",
      "        [-0.0912, -0.1185, -0.2301, -0.1536,  0.1782, -0.0390,  0.0818,  0.1029,\n",
      "         -0.1114,  0.2519,  0.1613, -0.2618,  0.1966],\n",
      "        [-0.3371,  0.1260, -0.0959,  0.1799, -0.1601, -0.0863, -0.0332,  0.0419,\n",
      "         -0.2219,  0.0070,  0.3476, -0.1767,  0.1130],\n",
      "        [ 0.3581,  0.1158, -0.1333, -0.3458, -0.3672,  0.0803,  0.3176,  0.0380,\n",
      "          0.2485, -0.3285, -0.0161,  0.1625, -0.3719],\n",
      "        [-0.1441, -0.0282, -0.1615, -0.3002,  0.1028, -0.0913,  0.1454, -0.2238,\n",
      "          0.1552,  0.0312, -0.2489,  0.0220, -0.0162],\n",
      "        [ 0.1319, -0.0952, -0.1548, -0.0778,  0.0075, -0.2197,  0.1388,  0.3000,\n",
      "         -0.0238,  0.2156,  0.1775,  0.1144,  0.2692],\n",
      "        [ 0.2311, -0.0924, -0.2047, -0.3079, -0.2587,  0.2411, -0.0737, -0.0732,\n",
      "          0.3678, -0.1780,  0.0408, -0.0772, -0.3197],\n",
      "        [ 0.2885, -0.0271, -0.1530,  0.2273, -0.1383,  0.0327, -0.1187, -0.3100,\n",
      "         -0.1936, -0.2403,  0.1274, -0.1463,  0.0546],\n",
      "        [ 0.0645, -0.1574,  0.1078,  0.3692, -0.1451,  0.1229,  0.1288, -0.1195,\n",
      "         -0.3291,  0.3191,  0.1982, -0.2109,  0.1875]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1600,  0.0367,  0.2059,  0.0839, -0.3223,  0.0327,  0.1686, -0.1521,\n",
      "        -0.2576,  0.1731,  0.0656, -0.0491, -0.0608,  0.0593,  0.0630,  0.1300,\n",
      "        -0.1443,  0.0729,  0.1818,  0.0615,  0.1032, -0.0084, -0.0569,  0.1394,\n",
      "        -0.1356,  0.0402], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9104, 0.9392, 0.9329, 0.9045, 0.8177, 0.7688, 0.9812, 0.9356, 0.9029,\n",
      "        0.9283, 0.6854, 1.0315, 1.0318, 0.8236, 1.0346, 0.9423, 0.9227, 0.8958,\n",
      "        0.9379, 0.9627, 1.0006, 0.9659, 0.8610, 0.9665, 0.9393, 1.0118],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0059, -0.0547, -0.0200,  0.0689,  0.0539, -0.1778,  0.0029,  0.0542,\n",
      "         0.0403,  0.0631, -0.3254, -0.0215, -0.0179, -0.0419, -0.0209, -0.0063,\n",
      "         0.0137, -0.0106,  0.0515,  0.0038,  0.0148, -0.0522,  0.0099, -0.0204,\n",
      "         0.0520, -0.0156], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0689, -0.0510,  0.1101,  0.0270, -0.0322, -0.0182,  0.0912, -0.0853,\n",
      "          0.0433, -0.0471, -0.0270,  0.2180,  0.1733,  0.0521,  0.2058,  0.0478,\n",
      "         -0.0997,  0.0920, -0.1055,  0.0883, -0.1558,  0.0372,  0.0422, -0.0832,\n",
      "         -0.1038,  0.1673]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0306], requires_grad=True)\n",
      "Critic_2\n",
      "Parameter containing:\n",
      "tensor([[ 0.3644,  0.2714,  0.1235, -0.1978],\n",
      "        [ 0.3686, -0.2149,  0.0360, -0.3913],\n",
      "        [ 0.1155,  0.2184, -0.0434, -0.4807],\n",
      "        [-0.1560,  0.2948,  0.3937,  0.2460],\n",
      "        [ 0.2741, -0.1584, -0.2364,  0.4833],\n",
      "        [ 0.0758, -0.4444,  0.3655,  0.2165],\n",
      "        [ 0.3010, -0.1396,  0.1199, -0.0250],\n",
      "        [ 0.3406, -0.0446, -0.2550,  0.4748],\n",
      "        [-0.0023,  0.1066,  0.2995, -0.2925],\n",
      "        [-0.0626,  0.2478, -0.0841,  0.4799],\n",
      "        [ 0.4243,  0.2343,  0.5210,  0.3209],\n",
      "        [-0.4683, -0.2043,  0.0670,  0.3765],\n",
      "        [-0.2844,  0.6240,  0.3285, -0.0529]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2323, -0.3419, -0.2283,  0.2868,  0.1654,  0.0839, -0.1298,  0.0518,\n",
      "        -0.4134,  0.4527, -0.3996, -0.1091,  0.4160], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9048, 1.0989, 0.8953, 0.9080, 1.0820, 1.1301, 0.9111, 0.9042, 0.9088,\n",
      "        0.8139, 0.9296, 1.0993, 1.0235], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0756, -0.0984, -0.0971, -0.0936, -0.0803, -0.1315,  0.0857,  0.0952,\n",
      "        -0.1051,  0.0461, -0.0822, -0.0990,  0.0163], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0091,  0.0526,  0.2351, -0.1545, -0.0049,  0.0832, -0.1347,  0.1456,\n",
      "         -0.1050,  0.0869,  0.0921,  0.0629, -0.0903],\n",
      "        [ 0.1343, -0.1336, -0.0061, -0.2298,  0.2725, -0.1773,  0.0370, -0.0864,\n",
      "         -0.0824,  0.2863, -0.3200,  0.0674, -0.3172],\n",
      "        [-0.1616,  0.0793, -0.1792, -0.0735, -0.2286,  0.0950,  0.2333,  0.0653,\n",
      "         -0.1972,  0.2096, -0.1758,  0.0334, -0.2447],\n",
      "        [-0.0616, -0.2195, -0.1612, -0.2064,  0.1457,  0.1278,  0.1171,  0.1672,\n",
      "         -0.2661,  0.1318,  0.1954, -0.1223, -0.1661],\n",
      "        [ 0.1826, -0.1094, -0.0709,  0.3374, -0.0046,  0.1938, -0.1519, -0.2111,\n",
      "         -0.1143,  0.0477,  0.2700,  0.0854,  0.1788],\n",
      "        [-0.0300, -0.3309,  0.2273, -0.1003, -0.0436,  0.0111,  0.0269, -0.0049,\n",
      "          0.3586,  0.0449, -0.0140, -0.2334,  0.0075],\n",
      "        [ 0.1087,  0.3147,  0.1389, -0.3546,  0.3630, -0.1725, -0.0360, -0.0663,\n",
      "          0.0573, -0.0769, -0.3067,  0.2921,  0.1392],\n",
      "        [ 0.1555,  0.1844, -0.2275, -0.1723, -0.0770, -0.1323,  0.0983,  0.0961,\n",
      "         -0.0943, -0.0378, -0.2335, -0.2453, -0.1004],\n",
      "        [-0.2442, -0.0438,  0.2713,  0.1306,  0.1786,  0.1030,  0.2067, -0.1109,\n",
      "          0.0116, -0.0596, -0.2390,  0.1070, -0.2269],\n",
      "        [-0.1990,  0.2649, -0.0489,  0.2147,  0.2476,  0.1712, -0.2384, -0.2632,\n",
      "         -0.0836,  0.0660,  0.0701,  0.0179, -0.0383],\n",
      "        [-0.1730, -0.2030,  0.1634, -0.0736,  0.1082,  0.0301,  0.2462,  0.1231,\n",
      "          0.1115, -0.1162,  0.1212, -0.1699, -0.2929],\n",
      "        [ 0.0045,  0.2797,  0.1067, -0.0286,  0.3540,  0.1821,  0.0049, -0.1436,\n",
      "         -0.3131,  0.1707,  0.0505,  0.3880,  0.1209],\n",
      "        [-0.1126,  0.1245,  0.2527, -0.0905,  0.0411,  0.1655,  0.2130, -0.0983,\n",
      "         -0.0239, -0.1808,  0.1760,  0.0702, -0.2257],\n",
      "        [-0.2393,  0.0980, -0.0860,  0.0926,  0.0074,  0.1088,  0.1191, -0.1702,\n",
      "          0.1744,  0.1755, -0.2023,  0.1226, -0.1697],\n",
      "        [-0.0037, -0.0215, -0.0441,  0.2766,  0.2478,  0.0180,  0.2293, -0.1603,\n",
      "         -0.1758, -0.0257,  0.0611,  0.1560, -0.1633],\n",
      "        [-0.1563,  0.2737,  0.2088,  0.1798, -0.1141,  0.2667, -0.1216,  0.1190,\n",
      "         -0.1165,  0.2655, -0.2286, -0.1231, -0.0957],\n",
      "        [ 0.3679, -0.3919,  0.0570, -0.0400, -0.3251, -0.3640, -0.0452,  0.0278,\n",
      "          0.2006,  0.0476,  0.1110,  0.1250,  0.2601],\n",
      "        [-0.0302,  0.0722, -0.1416,  0.1716, -0.1722, -0.2591, -0.2038, -0.3731,\n",
      "         -0.0397, -0.0115,  0.2336, -0.2331,  0.2625],\n",
      "        [ 0.1083, -0.3033,  0.1398, -0.0740,  0.1534, -0.3738, -0.3556, -0.3316,\n",
      "         -0.0246, -0.2100, -0.0164, -0.3144,  0.1768],\n",
      "        [ 0.0049, -0.1519,  0.1128,  0.2255, -0.1018,  0.2642, -0.2229, -0.0009,\n",
      "         -0.2674,  0.2271, -0.3201,  0.0175, -0.3128],\n",
      "        [-0.1535,  0.2622, -0.1168,  0.2383, -0.2586,  0.2732,  0.2357,  0.2234,\n",
      "          0.1448, -0.0674, -0.0972,  0.2477,  0.1420],\n",
      "        [-0.0463, -0.0407,  0.1436, -0.2745, -0.0161,  0.2214, -0.0488,  0.1495,\n",
      "         -0.2076, -0.2473, -0.0549, -0.1682, -0.0209],\n",
      "        [-0.1874,  0.2380, -0.1705,  0.0682, -0.0276, -0.1187, -0.1679,  0.1834,\n",
      "          0.0883, -0.0472, -0.2691,  0.1983, -0.2412],\n",
      "        [-0.0948, -0.1977,  0.2366,  0.1771,  0.0728, -0.3764, -0.2705, -0.0770,\n",
      "         -0.0567, -0.0404, -0.1473, -0.3842,  0.2167],\n",
      "        [ 0.1130,  0.0896, -0.1753,  0.2539, -0.0653,  0.2033,  0.2636,  0.2330,\n",
      "         -0.0706,  0.2199, -0.1383, -0.2417, -0.1651],\n",
      "        [-0.0743, -0.0312, -0.3195, -0.3093, -0.1317,  0.1251, -0.1336,  0.2121,\n",
      "          0.1236,  0.1208, -0.1924, -0.0527, -0.2818]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1241, -0.0028,  0.1759, -0.1471,  0.1081,  0.1798, -0.1115, -0.0393,\n",
      "        -0.2334,  0.0173,  0.0198,  0.0539, -0.2451, -0.1996,  0.2011, -0.1875,\n",
      "         0.2597,  0.1504,  0.2914, -0.0870,  0.2642, -0.1577,  0.1914,  0.3257,\n",
      "        -0.1873,  0.0354], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0495, 1.0071, 0.8740, 1.0527, 0.7625, 0.8743, 0.8508, 1.0534, 0.8732,\n",
      "        1.0838, 0.8080, 0.8778, 1.0795, 0.8384, 1.0387, 0.8806, 1.0586, 1.0537,\n",
      "        1.0688, 1.0788, 0.8747, 1.0709, 1.0879, 1.0653, 1.0849, 1.0708],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0418, -0.0115,  0.1321, -0.0447,  0.0214,  0.0377, -0.0257, -0.0454,\n",
      "         0.1286, -0.0753,  0.1513, -0.0688, -0.0709, -0.0283, -0.0320,  0.1172,\n",
      "         0.0786,  0.0725,  0.0816, -0.0735,  0.1260, -0.0621, -0.0797,  0.0740,\n",
      "        -0.0765,  0.0806], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1213, -0.0900, -0.0572, -0.1254,  0.0351, -0.0205,  0.0216, -0.1264,\n",
      "          0.0013, -0.2207, -0.0254, -0.0131, -0.1947, -0.0021, -0.1099,  0.0655,\n",
      "          0.2568,  0.2228,  0.2589, -0.2080,  0.0120, -0.1610, -0.2590,  0.2325,\n",
      "         -0.2296,  0.1048]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0266], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check the init params of actor and two critics\n",
    "print('Actor')\n",
    "for param in agent.actor.parameters():\n",
    "    print(param)\n",
    "    \n",
    "print('Critic_1')\n",
    "for param in agent.critic_1.parameters():\n",
    "    print(param)\n",
    "    \n",
    "print('Critic_2')\n",
    "for param in agent.critic_2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "baf7a57c528b90bfd786fcd04486c8c2dfc7aaff4a71b2812269de64341c9123"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
